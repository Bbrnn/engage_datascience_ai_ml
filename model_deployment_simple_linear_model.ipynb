{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bbrnn/engage_datascience_ai_ml/blob/main/model_deployment_simple_linear_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxmiafBwF4sk"
      },
      "source": [
        "<h2>MODEL DEPLOYMENT</h2>\n",
        "\n",
        "By the end of this module the learner should be able to:\n",
        "1. Define model deployment.\n",
        "2. Distinguish between the different deployment models.\n",
        "3. Identify the various deployment environments.\n",
        "4. Create a web app using streamlit.\n",
        "5. Create a model\n",
        "6. Integrate a model into an application.\n",
        "\n",
        "<h2>Definition of model deployment</h2>\n",
        "\n",
        "Lets us start by thinking about what model deployment is all about. When we create the models in our jupyter notebooks or R environment, we are not able to share this with the people who want to constantily use them for the machine learning tasks such as predictions, classification and so on. We therefore need to make our models accessible for the actual users to be able to use them. This process of availing our models to potential users is what is reffered to us **model deployment**.\n",
        "\n",
        "Deploying a  model will involve integrating it with existing applications. For example if you were building a machine learning model to help doctors diagnosize patients with diabetics, you will need to integrate it with the existing health management system used in the hospital or you will need to develop an application that will help the doctor put the patients sysmptoms and then this information is sent to the model through an API (Intergreted application interface). The model then serves the request and sends the prediction to the doctor.\n",
        "\n",
        "As much as model deployment is the last stage in the machine learning cycle, model deployment is the first step in what is reffered to us model management.\n",
        "\n",
        "A typical cycle for machine learning model management is shown in the diagram below;\n",
        "\n",
        "\n",
        "The first step  involves the deployment of the model. Once the model is deployed, its performance is monitored. If the performance of the model reduces to a cerain level, the model will require retraining and evaluation and so that the old model can be replaced with a new model.\n",
        "\n",
        "<h3>Why deploy the models</h3>\n",
        "\n",
        "- Model deployment is the final step in the machine learning pipeline, where the model transitions from a development/testing phase to real-world usage.\n",
        "- Deployed models enable organizations to automate decision-making processes, optimize workflows, and derive actionable insights from data.\n",
        "- Efficient deployment ensures that the benefits of machine learning models are realized in practical applications, leading to improved efficiency, accuracy, and competitiveness.\n",
        "\n",
        "<h2>Machine learning model deployment models</h2>\n",
        "\n",
        "In general, there are 3 ways you can deploy our trained machine learning model.\n",
        "\n",
        "1. one off\n",
        "The one off model is applicable in cases where the model is only required at one particular time. This is appliable if the model is required for a temporary task. This can be applicable in a scenerio where for example if the governemnt is rolling out vaccination lets say for measals, they can develop a model for predicting the people at high risk for priotizing the distribution of the vaccine.\n",
        "\n",
        "2. Batch\n",
        "The batch model allows you to have an updated version of the model at all times. This is useful in cases where you do not need predictions done on real time data. The model gets trained on the whole dataset at certain period and used for prediction. An applicable area can be in disease servillance where the data is collected periodically like monthly and used in training the model.\n",
        "3. Realtime\n",
        "\n",
        "Realtime deployment is applicable where predictions are needed in realtime. Realtime deployment of the machine learning model can be applicable in cases such as disease servillance in case of pandemics where you might want to know everytime where new cases are reported.\n",
        "\n",
        "<h2>Factors to consider when choosing a model deployment model</h2>\n",
        "\n",
        "- How frequent/often are the predictions required and how urgent the results are required\n",
        "\n",
        "- Do we need individualpredictions or batch predictions\n",
        "\n",
        "- Cost of deploying the model\n",
        "- Computing capabilities required by the model\n",
        "- The complexity of the model. Realtime deployment model requires less complex models\n",
        "\n",
        "<h2>Challenges in machine learning model deployment</h2>\n",
        "\n",
        "- The discrepancies in programming langauges: As you have noted by now machine learning models mostily using R or Python but most applications that the model need to be integreated into are written in other langauges such as Java, PhP, type script, Ruby, C#. The integration of the models to this applications may pose a challenge.\n",
        "\n",
        "- Model drift: When the performance of a machine learning model degrades to a level that is below the benchmark, it is reffered to us model drift. Depending on the use of the model, the degradation of the model performance can cause a major impact expecially in the medical field. It is therefore very important to be able to monitor the performance of machine learning models so that any degradation in performance can be captured at an early stage. Model degradation can be caused by:\n",
        "\n",
        "1. Changing data behavior: In a typical machine learning model creation, the model is trained using historical data which is in a particular format but we know data data can change and the machine learning model will be exposed with data it has not seen before hence the poor performance. For example if a machine learning was trained to identify wheather someone had covid-19 using the data collected in 2019 which had various symptoms. At the beginning the machine learning model will perform well when patients present with the same symptoms the model was trained for. But over time when new variants of Covid-19 with different symptoms arise, the model may fail to identify if a person has Covid-19 based on the new symptoms. In such cases when there is a degredation of the performance of the model, is important to train the model on the emwrging data  or new data.\n",
        "\n",
        "2. Changing interpretation of the new data (Concept drift): Concept drift happens when the clasification of an outcome variable changes in meaning. For example if previous target variable for the machine learning model for covid during the early stages was either someone had covid or not. But with the emergence of the new variants more outcome variable are available. Instead of just wanting to know if someone has covid or not, one will be interested to find the covid variant that soemone is suffering from based on the symptoms. With such change it is important to retrain the model with the new knowledge.\n",
        "\n",
        "3. Deploying the model on the cloud or on premise: Just like the discussion on whether to adopt cloud compputing or deploy applications on premise, the decisons of where the model will be hosted has trendoffs to be made. The issues of security, privacy and accessibility will suffice.\n",
        "4. Model monitoring: It is important to have model monitorin plan. This will help in being able to determine the threshold of the model performance. If there is no plan, there is a danger of failing to monitor the performance of the model.\n",
        "\n",
        "5. Vesrion control: With the fact that the machine learning model will need to be retrained, it is important to keep tab of the versions of the model so that in case of anything you can always go back to the previous working version. One of the most common used version control tools is called Github.\n",
        "\n",
        "\n",
        "<h2>Deployment environments</h2>\n",
        "\n",
        "1. streamlit\n",
        "2. Heroku\n",
        "3. TensorFlow Serving with Docker\n",
        "4. AWS\n",
        "5. Microsoft Azure\n",
        "\n",
        "These are just a few places where you can deploy your machine learning model. You can explore more deployment environments.\n",
        "\n",
        "<h2>Steps for deploying a machine learning model</h2>\n",
        "\n",
        "1. Training of the model\n",
        "2. Saving the model\n",
        "3. Select the deployment environment\n",
        "4. Set up the requirements: These are dependancies that the model depends on such as all the libraries that were imported.\n",
        "5. Serve the model using REST API such as flask, Django, FastAPI or streamlit\n",
        "6. Deploy the model in the selected environment such as heroku server, AWS e.tc.\n",
        "7. Create the interface to access the model such as a webform\n",
        "\n",
        "Lets go through the process listed above using an example for predicting the probablity that someone has cholera or not?\n",
        "\n",
        "<h2>Machine learning deployment as a web service</h2>\n",
        "\n",
        "As we have already learnt, we mainly test and train our machine learning models using Google Colab/jupyter notebook but if we require to conect our model to an app or web service, we will need to deploy it as a webserver. This server can either be in the cloud or on premise. In this section, we are going to explore how to deploy our model Using streamlit.\n",
        "\n",
        "** Introduction to Streamlit**\n",
        "\n",
        "Streamlit is an easy to use open-source Python library used to create and share custom web apps for machine learning and data science projects. It allows you to turn your trained models into shareable web apps in minutes, without needing extensive web development skills.\n",
        "\n",
        "A web application, is an application that you can access using the browser\n",
        "\n",
        "Before we use streamlit to deploy our model, we will need to first of all install it. To install it, we will use pip which you were introduced to in the first chapter. The code to install streamlit is as follows\n",
        "\n",
        "    pip install streamlit\n",
        "If you already have it in the machine, you will get the message \"requirements satisified\"\n",
        "\n",
        "Let's start by learning a few commands that you can use in streamlit by creating the hello world web app."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNq_U7SjQbFk",
        "outputId": "795b3fd4-c7d8-460f-9bd1-a4255fd37f3e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.37.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.37.1-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.37.1 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "# Title of the app\n",
        "st.title('Hello World Streamlit App')\n",
        "\n",
        "# Display text\n",
        "st.write('Hello, World! This is my first Streamlit app.')\n",
        "\n",
        "# Add a slider widget\n",
        "number = st.slider('Pick a number', 0, 100, 50)\n",
        "st.write('You selected:', number)"
      ],
      "metadata": {
        "id": "l9bUTiL_Qhvt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYzNSqHUGgHb"
      },
      "source": [
        "**Code explanation**\n",
        "\n",
        "The **st. title** method helps to write a title for our application\n",
        "\n",
        "The **st.write\"** is used to write any thing to the screen\n",
        "\n",
        "The **st.slider** will create a slider for you that you can be able to drag through.\n",
        "\n",
        "To see how our app is working, we will transfer the code above to a text editor and save it as app.py then we will use the streamlit run command to run our file from the command prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK3hao2vGlmP"
      },
      "source": [
        "\n",
        "**<h2>CREATING AN APP FOR RUNNING A MODEL</h2>**\n",
        "\n",
        "Now that we know the basic streamlit, lets deploy the model using the stramlit app.\n",
        "\n",
        "**<h4>Importing the libraries</h4>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLqC3RATGZNQ",
        "outputId": "16226017-45cb-42ab-d85e-f402ed7afc28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrFDFqBOG0bp",
        "outputId": "a48cac83-c0fa-4f04-c31d-021c90fdcb54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "2024-08-22 09:18:15.026 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ],
      "source": [
        "# Importing the necessary libraries\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Loading your saved model. Be sure to change the path if needed\n",
        "model = joblib.load('/content/drive/My Drive/ENGAGE/Datasets/SimpleLinearRegressionPractical/simple_linear_regression_model_practical.joblib')\n",
        "\n",
        "st.title('Child Height Prediction App')\n",
        "st.write(\"This app predicts a child's height based on the child's age.\")\n",
        "\n",
        "# Input fields\n",
        "age_1 = st.number_input('Age', min_value=0.0, max_value=100.0, value=6.0)\n",
        "# Binary features using selectbox\n",
        "###sex_1 = st.selectbox('Sex', options=[0, 1], index=0)\n",
        "###area_1 = st.selectbox('Area', options=[0, 1], index=0)\n",
        "\n",
        "# Categorical feature with options 0 through 4\n",
        "###wealth_1 = st.selectbox('Wealth Index Quintile', options=[0, 1, 2, 3, 4], index=0)\n",
        "\n",
        "# Create a button to trigger prediction\n",
        "if st.button('Predict'):\n",
        "    # Prepare input features for prediction\n",
        "    input_features = np.array([[age_1]])#for single input or simple linear model\n",
        "   ### input_features = np.array([[age_1, sex_1, area_1, wealth_1]])  # Ensure this is a 2D array\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_features)\n",
        "\n",
        "    # Display prediction\n",
        "    #st.write(f'Predicted weight: {prediction[0]:.2f}')\n",
        "    st.write(f'Predicted height: {[prediction][0]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mueQOVqkJji9"
      },
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeXXmFRPJp_j",
        "outputId": "a1f4876d-c887-4195-9148-e6973b8c0d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 2s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEs6Yg6UJqqk"
      },
      "outputs": [],
      "source": [
        "#steamlit run /content/simple_linear_regression_model_practical.py &>/content/simple_linear_regression_model_practical_logs.txt &\n",
        "!streamlit run /content/start.py &>/content/start_logs.txt &\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq5-Y2ftS40f",
        "outputId": "2f10cbfa-539c-4b65-9af2-631a294e21fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://spotty-eels-joke.loca.lt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}